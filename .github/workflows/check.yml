name: Scraper diario de vuelos

on:
  schedule:
    - cron: '0 8 * * *'  # Todos los dÃ­as a las 08:00 UTC
  workflow_dispatch:     # EjecuciÃ³n manual desde GitHub

jobs:
  scrape-and-send:
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ“¥ Clonar repositorio
        uses: actions/checkout@v3

      - name: âš™ï¸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ðŸ“¦ Instalar dependencias y Chromium
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo apt-get update
          sudo apt-get install -y chromium-browser
          sudo apt-get install -y chromium-chromedriver
          if [ ! -L /usr/bin/chromedriver ]; then
            sudo ln -s /usr/lib/chromium-browser/chromedriver /usr/bin/chromedriver
          fi

      - name: ðŸ” Exportar contraseÃ±a de email desde Secret
        run: echo "EMAIL_ACCESS_CODE=${{ secrets.EMAIL_ACCESS_CODE }}" >> $GITHUB_ENV

      - name: ðŸ§ª Ejecutar el scraper
        run: python scripts/check_flights_scraper.py
        env:
          EMAIL_ACCESS_CODE: ${{ secrets.EMAIL_ACCESS_CODE }}

