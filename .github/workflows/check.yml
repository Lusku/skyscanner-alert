name: Scraper diario de vuelos

on:
  schedule:
    - cron: '0 8 * * *'  # Todos los d칤as a las 08:00 UTC
  workflow_dispatch:     # Ejecuci칩n manual desde GitHub

jobs:
  scrape-and-send:
    runs-on: ubuntu-latest

    steps:
      - name: 游닌 Clonar repositorio
        uses: actions/checkout@v3

      - name: 丘뙖잺 Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: 游빍 Diagn칩stico de chromedriver
        run: |
          echo "Comprobando ubicaci칩n de chromedriver..."
          which chromedriver || echo "chromedriver no est치 en el PATH"
          chromedriver --version || echo "chromedriver no se puede ejecutar"
          find / -name chromedriver 2>/dev/null || echo "No encontrado en el sistema"

      - name: 游닍 Instalar dependencias y Chromium
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo apt-get update
          sudo apt-get install -y chromium-browser
          sudo apt-get install -y chromium-chromedriver

      - name: 游댌 Verificar que Chromedriver est치 disponible
        run: chromedriver --version

      - name: 游댏 Exportar contrase침a de email desde Secret
        run: echo "EMAIL_ACCESS_CODE=${{ secrets.EMAIL_ACCESS_CODE }}" >> $GITHUB_ENV

      - name: 游빍 Ejecutar el scraper
        run: python scripts/check_flights_scraper.py
        env:
          EMAIL_ACCESS_CODE: ${{ secrets.EMAIL_ACCESS_CODE }}

